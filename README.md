# üõí An√°lise de Sentimento - Amazon Reviews 2023

![Python](https://img.shields.io/badge/Python-3.10-blue?style=for-the-badge&logo=python)
![Scikit-Learn](https://img.shields.io/badge/Scikit_Learn-F7931E?style=for-the-badge&logo=scikit-learn)
![NLTK](https://img.shields.io/badge/NLTK-3e6f96?style=for-the-badge&logo=nltk)
![Pandas](https://img.shields.io/badge/Pandas-150458?style=for-the-badge&logo=pandas)

## üìå Vis√£o Geral

Este projeto aplica t√©cnicas de **Processamento de Linguagem Natural (NLP)** e **Machine Learning** para classificar avalia√ß√µes de produtos da Amazon. O objetivo √© prever automaticamente se um coment√°rio √© **Positivo** ou **Negativo** com base apenas no texto escrito pelo usu√°rio.

O projeto compara dois algoritmos cl√°ssicos: **Naive Bayes** (como baseline) e **Regress√£o Log√≠stica**, demonstrando como o pr√©-processamento correto e a escolha do modelo impactam a m√©trica final.

---

## üóÇÔ∏è O Dataset

Foi utilizada a base de dados **Amazon Reviews 2023**, focando apenas em compras verificadas (*Verified Purchases*) para garantir a qualidade da informa√ß√£o.

* **Entrada:** Texto do review (`text`) e T√≠tulo (`title`).
* **Target (Sentimento):**
    * üëç **Positivo (1):** Notas 4 e 5.
    * üëé **Negativo (0):** Notas 1 e 2.
    * *Notas 3 foram descartadas por ambiguidade.*

---

## ‚öôÔ∏è Pipeline de NLP

Antes da modelagem, o texto bruto passou por um tratamento rigoroso para reduzir ru√≠dos:

1.  **Limpeza (Regex):** Remo√ß√£o de pontua√ß√µes, n√∫meros e tags HTML.
2.  **Normaliza√ß√£o:** Convers√£o para min√∫sculas (lowercase).
3.  **Stopwords:** Remo√ß√£o de palavras comuns (ex: "the", "is", "and") usando NLTK.
4.  **Lematiza√ß√£o:** Redu√ß√£o das palavras √† sua raiz lingu√≠stica (ex: "better" -> "good").
5.  **Vetoriza√ß√£o (TF-IDF):** Transforma√ß√£o do texto em vetores num√©ricos ponderados pela frequ√™ncia inversa nos documentos.



## üìä An√°lise Explorat√≥ria (EDA)

Investigamos se o **tamanho do texto** influenciava o sentimento.

**Insights:**
* **Desbalanceamento:** O gr√°fico mostra um volume muito maior de avalia√ß√µes positivas (verde) em rela√ß√£o √†s negativas (azul), o que √© comum em e-commerce.
* **Padr√£o de Escrita:** A distribui√ß√£o √© similar para ambos os sentimentos. A maioria dos usu√°rios escreve textos curtos (cauda longa √† direita), indicando que o tamanho do review n√£o √©, isoladamente, um bom previsor do sentimento.

---

## ü§ñ Modelagem e Resultados

Foram testados dois modelos. O **Naive Bayes** serviu como linha de base (baseline) para compara√ß√£o com a **Regress√£o Log√≠stica**.

### 1. Baseline: Multinomial Naive Bayes
O modelo obteve uma acur√°cia de **87.8%**. Abaixo, vemos a matriz de confus√£o deste modelo:

![Matriz de Confus√£o Naive Bayes](assets/matriz_confusao_nb.png)

> *Nota-se que, apesar de acertar bem os positivos (88k acertos), o modelo confunde uma quantidade consider√°vel de negativos como positivos (Falsos Positivos).*

### 2. Modelo Final: Logistic Regression
A Regress√£o Log√≠stica superou o baseline, lidando melhor com a complexidade dos dados e o desbalanceamento das classes.

| Modelo | Acur√°cia | F1-Score (Negativo) | F1-Score (Positivo) |
| :--- | :---: | :---: | :---: |
| Naive Bayes | 87.81% | 0.66 | 0.93 |
| **Logistic Regression** | **91.46%** | **0.80** | **0.95** |


Conclus√£o: A Regress√£o Log√≠stica aumentou a capacidade de detec√ß√£o da classe minorit√°ria (reviews negativos), subindo o F1-Score de 0.66 para 0.80, provando ser a solu√ß√£o mais robusta para este problema.

üë®‚Äçüíª Autor

Alexander Lira Data Analyst | Python | Machine Learning
